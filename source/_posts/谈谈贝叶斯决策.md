title: 谈谈贝叶斯决策
date: 2015-07-14 09:44:57
tags: 
- 贝叶斯
- 分类
- 机器学习
categories: 
- 技术
---

# 谈谈贝叶斯决策
**贝叶斯决策**是一种常用的分类方法，模型复杂度低，分类效果好，在实际应用中可以和多种分类方法结合。同时，它有着最高的理论正确率（这一点自动化所的模式识别课程中多次强调）。
现在写一写自己在学习使用贝叶斯方法中的几点理解，这并不是一个事无巨细总结，而是一个简单的脉络，方便自己回顾，也与大家分享。


-------------------
##先验概率与后验概率
首先得先谈谈这两个概念：
- `先验概率`： 事情还没有发生，要求这件事情发生的可能性的大小。如P(A).
- `后验概率`： 事情已经发生，要求这件事情发生的原因是由某个因素引起的可能性的大小，是后验概率. 

所以我们可以使用贝叶斯公式求后验概率，进而达到分类的目的。
##公式
重中之重肯定是贝叶斯公式。

### 贝叶斯公式

$$	P(F_j|E)= \dfrac{P(F_jE)}{P(E)} =  \dfrac{P(E|F_j)P(F_j)}{ \displaystyle{\sum_{i=1}^{n} }P(E|F_i)P(F_i) }$$

上式写成这个形式有两个重点：
- **推导核心**：条件概率公式。分解中间步骤分子，我们得出结果$P(F_j|E) \cdot P(E)= P(F_jE) =   P(E|F_j) \cdot P(F_j)$.   

- **应用思想**：用于分类问题。分解中间步骤分母$P(E) = \displaystyle{\sum_{i=1}^{n} }P(E|F_i)P(F_i）$ ，每个$F_i$代表一个类别。

这里扯一点偏的，条件概率公式对任意两个事件都是存在的，当两事件独立(即$P(EF) = P(E)P(F)$)时，$P(E|F) = P(EF)/P(F) = P(E)$.



##一个例子
看过很多讲解贝叶斯公式的例子，感觉下面这个很好，因为他抓住了这个公式的灵魂。
> 一份信件等可能的在存在三个不同的文件夹中的任意一个。假设信件实际在文件夹$i$中$(i = 1,2,3)$而你经过对文件夹$i$的快速翻阅发现信件的概率记为$a_i$，问题是，假定你查看了文件夹1且没有发现此信，问信件在文件夹1中的概率是多少？
                                                              ——[《应用随机过程：概率模型导论》](http://book.douban.com/subject/2309401/)

**解**： 以$F_i(i = 1,2,3)$为信在文件中$i$中的事件`（先验概率）`，E是通过对文件夹1搜索而为看到信这个事件，我们求$P(F_1|E)$`(后验概率)`，通过贝叶斯公式：
$$	P(F_1|E)=  \dfrac{P(E|F_1)P(F_1)}{ \displaystyle{\sum_{i=1}^{3} }P(E|F_i)P(F_i) } = \dfrac{(1-a_1) \frac{1}{3}}{ (1-a_1) \frac{1}{3}+\frac{1}{3}+\frac{1}{3}} = \dfrac{1-a_1}{3-a_1}$$


这个例子有两个重点，一个是对问题中两个事件的假设，里一个是对整体事件空间`(分母)`的分类


##使用
其实贝叶斯思想只是一个框架，有很多使用方法与模型，但大部分都是基于概率论的分类方法。
朴素思分类就是一个通过先验概率求后验概率的方法，然后将实例点分到后验概率最大的类，就像街上有一个黑人，我们预测黑人来自非洲，为什么呢？因为黑人中非洲人的比率最高。
###朴素贝叶斯的两个核心假设：
1. 特征之间相互独立 ：这个“朴素”一词的来源。假设体现在向量的特征之间。所以有
$$P(x|y_i)P(y_i)=P(a_1|y_i)P(a_2|y_i)...P(a_m|y_i)P(y_i)=P(y_i)\prod^m_{j=1}P(a_j|y_i)$$
 * $y_i$为每一个类别，$a_i$ 为样本X的特征的每一维分量
2. 每个特征同等重要。


##分类准则
将输入向量分到后验概率最大的类，这就是分类准则。贝叶斯使用的是`最大后验概率准则`。
在别的分类方法中，我们还用过`最小错误率`的分类准则，比如基于0-1损失的最小错误率，这两者是一样的。

设损失函数$$ L(Y,f(X))  =\left\{\begin{aligned}
1,Y\not= f(X)\\
0, Y= f(X) \\
\end{aligned} \right. $$
期望风险函数
  $R_e(f(x)) = E[L(Y, f(x))]$
=  $\iint_{X,Y}L(Y,f(X))P(X,Y)\mathrm{d}x\mathrm{d}y$
= $\iint_{X,Y}L(Y,f(X))P(Y|X)P(X)\mathrm{d}x\mathrm{d}y$
= $\int_{X} (\sum_{k=1}^{k}L(Y= c_k,f(X))P(Y=c_k|X) )P(X)\mathrm{d}x$
= $E_x(\sum_{k=1}^{k}L(Y= c_k,f(X))P(Y=c_k|X) )$

为了使期望最小，对$X=x$逐个极小化：
$f(x) = \arg\min \limits_{y\in\mathcal{Y}}\sum_{k=1}^{k}L(c_k,y)P(c_k|X=x) $
= $ \arg\min \limits_{y\in\mathcal{Y}}\sum_{k=1}^{k}P(y \not = c_k|X=x) $
= $ \arg\min \limits_{y\in\mathcal{Y}}\sum_{k=1}^{k}(1-P(y  = c_k|X=x) )$
= $ \arg\max \limits_{y\in\mathcal{Y}} P(y = c_k|X = x)$
= 后验概率最大准则


Robin 
2015.7.10 夜 
